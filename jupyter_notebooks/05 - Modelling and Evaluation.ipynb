{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8228f95c",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94d09ac",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "*   Fit and evaluate a regression model to predict tenure levels for a prospect that will predict sale price\n",
    "\n",
    "\n",
    "## Inputs\n",
    "\n",
    "* outputs/datasets/collection/HousePriceRecords.csv\n",
    "* Instructions on which variables to use for data cleaning and feature engineering. They are found in their respective notebooks.\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* Train set (features and target)\n",
    "* Test set (features and target)\n",
    "* ML pipeline to predict Sale Price\n",
    "* labels map\n",
    "* Feature Importance Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b322bb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8b7569",
   "metadata": {},
   "source": [
    "# Change working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c276af77",
   "metadata": {},
   "source": [
    "We need to change the working directory from its current folder to its parent folder\n",
    "* We access the current directory with os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdc33e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/p5test/jupyter_notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92305b5a",
   "metadata": {},
   "source": [
    "We want to make the parent of the current directory the new current directory.\n",
    "* os.path.dirname() gets the parent directory\n",
    "* os.chir() defines the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1f3c006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You set a new current directory\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27240028",
   "metadata": {},
   "source": [
    "Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ca3561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/p5test'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8887717",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a3304c",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec25611",
   "metadata": {},
   "source": [
    "Drop 'EnclosedPorch' and 'WoodDeckSF' as missing data was over 80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82dac84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>...</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>856</td>\n",
       "      <td>854.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>No</td>\n",
       "      <td>706</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>150</td>\n",
       "      <td>548</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8450</td>\n",
       "      <td>65.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>856</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>978</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>284</td>\n",
       "      <td>460</td>\n",
       "      <td>RFn</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9600</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1262</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>920</td>\n",
       "      <td>866.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Mn</td>\n",
       "      <td>486</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>434</td>\n",
       "      <td>608</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11250</td>\n",
       "      <td>68.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>920</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>961</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>216</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>540</td>\n",
       "      <td>642</td>\n",
       "      <td>Unf</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9550</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>756</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Av</td>\n",
       "      <td>655</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>490</td>\n",
       "      <td>836</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14260</td>\n",
       "      <td>84.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>84</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1145</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  BedroomAbvGr BsmtExposure  BsmtFinSF1 BsmtFinType1  \\\n",
       "0       856     854.0           3.0           No         706          GLQ   \n",
       "1      1262       0.0           3.0           Gd         978          ALQ   \n",
       "2       920     866.0           3.0           Mn         486          GLQ   \n",
       "3       961       NaN           NaN           No         216          ALQ   \n",
       "4      1145       NaN           4.0           Av         655          GLQ   \n",
       "\n",
       "   BsmtUnfSF  GarageArea GarageFinish  GarageYrBlt  ...  LotArea LotFrontage  \\\n",
       "0        150         548          RFn       2003.0  ...     8450        65.0   \n",
       "1        284         460          RFn       1976.0  ...     9600        80.0   \n",
       "2        434         608          RFn       2001.0  ...    11250        68.0   \n",
       "3        540         642          Unf       1998.0  ...     9550        60.0   \n",
       "4        490         836          RFn       2000.0  ...    14260        84.0   \n",
       "\n",
       "   MasVnrArea  OpenPorchSF  OverallCond  OverallQual  TotalBsmtSF  YearBuilt  \\\n",
       "0       196.0           61            5            7          856       2003   \n",
       "1         0.0            0            8            6         1262       1976   \n",
       "2       162.0           42            5            7          920       2001   \n",
       "3         0.0           35            5            7          756       1915   \n",
       "4       350.0           84            5            8         1145       2000   \n",
       "\n",
       "   YearRemodAdd  SalePrice  \n",
       "0          2003     208500  \n",
       "1          1976     181500  \n",
       "2          2002     223500  \n",
       "3          1970     140000  \n",
       "4          2000     250000  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = (pd.read_csv(\"outputs/datasets/collection/HousePriceRecords.csv\")\n",
    "      .drop(labels=['EnclosedPorch', 'WoodDeckSF'], axis=1)\n",
    "      )\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35b36b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce3f8aed",
   "metadata": {},
   "source": [
    "# MP Pipeline: Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6061ea",
   "metadata": {},
   "source": [
    "## Create ML pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b5df1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Feature Engineering\n",
    "from feature_engine.encoding import OrdinalEncoder\n",
    "from feature_engine.selection import SmartCorrelatedSelection\n",
    "\n",
    "# Feat Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Feat Selection\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# ML algorithms\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "\n",
    "def PipelineOptimization(model):\n",
    "    pipeline_base = Pipeline([\n",
    "\n",
    "        (\"OrdinalCategoricalEncoder\", OrdinalEncoder(encoding_method='arbitrary',\n",
    "                                                     variables=['BsmtExposure', 'BsmtFinType1', 'GarageFinish', 'KitchenQual'])),\n",
    "\n",
    "\n",
    "        (\"SmartCorrelatedSelection\", SmartCorrelatedSelection(variables=None,\n",
    "         method=\"spearman\", threshold=0.6, selection_method=\"variance\")),\n",
    "\n",
    "        (\"feat_scaling\", StandardScaler()),\n",
    "\n",
    "        (\"feat_selection\",  SelectFromModel(model)),\n",
    "\n",
    "        (\"model\", model),\n",
    "\n",
    "    ])\n",
    "\n",
    "    return pipeline_base\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb29b6e",
   "metadata": {},
   "source": [
    "Custom Class for hyperparameter optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4514fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "class HyperparameterOptimizationSearch:\n",
    "\n",
    "    def __init__(self, models, params):\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
    "            model = PipelineOptimization(self.models[key])\n",
    "\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=scoring)\n",
    "            gs.fit(X, y)\n",
    "            self.grid_searches[key] = gs\n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                'estimator': key,\n",
    "                'min_score': min(scores),\n",
    "                'max_score': max(scores),\n",
    "                'mean_score': np.mean(scores),\n",
    "                'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params, **d})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]\n",
    "                scores.append(r.reshape(len(params), 1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params, all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "\n",
    "        columns = ['estimator', 'min_score',\n",
    "                   'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "\n",
    "        return df[columns], self.grid_searches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3231d8",
   "metadata": {},
   "source": [
    "## Split Train Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06d58b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Train set: (1168, 21) (1168,) \n",
      "* Test set: (292, 21) (292,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(['SalePrice'], axis=1),\n",
    "    df['SalePrice'],\n",
    "    test_size=0.2,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "print(\"* Train set:\", X_train.shape, y_train.shape,\n",
    "      \"\\n* Test set:\",  X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2313a905",
   "metadata": {},
   "source": [
    "## Grid Search CV - Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af38815",
   "metadata": {},
   "source": [
    "### Use default hyperparameters to find most suitable algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6927cf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_quick_search = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    \"DecisionTreeRegressor\": DecisionTreeRegressor(random_state=0),\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(random_state=0),\n",
    "    \"ExtraTreesRegressor\": ExtraTreesRegressor(random_state=0),\n",
    "    \"AdaBoostRegressor\": AdaBoostRegressor(random_state=0),\n",
    "    \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0),\n",
    "    \"XGBRegressor\": XGBRegressor(random_state=0),\n",
    "}\n",
    "\n",
    "params_quick_search = {\n",
    "    'LinearRegression': {},\n",
    "    \"DecisionTreeRegressor\": {},\n",
    "    \"RandomForestRegressor\": {},\n",
    "    \"ExtraTreesRegressor\": {},\n",
    "    \"AdaBoostRegressor\": {},\n",
    "    \"GradientBoostingRegressor\": {},\n",
    "    \"XGBRegressor\": {},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d726fb20",
   "metadata": {},
   "source": [
    "Do a hyperparameter optimisation search using default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e504fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running GridSearchCV for LinearRegression \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 423, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 377, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/joblib/memory.py\", line 326, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 957, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/utils/_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/base.py\", line 919, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/feature_engine/encoding/ordinal.py\", line 202, in fit\n    self._check_na(X, variables_)\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/feature_engine/encoding/base_encoder.py\", line 113, in _check_na\n    _check_optional_contains_na(X, variables)\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/feature_engine/dataframe_checks.py\", line 292, in _check_optional_contains_na\n    raise ValueError(\nValueError: Some of the variables in the dataset contain NaN. Check and remove those before using this transformer or set the parameter `missing_values='ignore'` when initialising this transformer.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m search \u001b[38;5;241m=\u001b[39m HyperparameterOptimizationSearch(models\u001b[38;5;241m=\u001b[39mmodels_quick_search, params\u001b[38;5;241m=\u001b[39mparams_quick_search)\n\u001b[0;32m----> 2\u001b[0m \u001b[43msearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 20\u001b[0m, in \u001b[0;36mHyperparameterOptimizationSearch.fit\u001b[0;34m(self, X, y, cv, n_jobs, verbose, scoring, refit)\u001b[0m\n\u001b[1;32m     17\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[key]\n\u001b[1;32m     18\u001b[0m gs \u001b[38;5;241m=\u001b[39m GridSearchCV(model, params, cv\u001b[38;5;241m=\u001b[39mcv, n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[1;32m     19\u001b[0m                   verbose\u001b[38;5;241m=\u001b[39mverbose, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrid_searches[key] \u001b[38;5;241m=\u001b[39m gs\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1422\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    870\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    873\u001b[0m     )\n\u001b[0;32m--> 875\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    408\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    412\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    413\u001b[0m     )\n\u001b[0;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    418\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    419\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    424\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 423, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 377, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/joblib/memory.py\", line 326, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 957, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/utils/_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/base.py\", line 919, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/feature_engine/encoding/ordinal.py\", line 202, in fit\n    self._check_na(X, variables_)\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/feature_engine/encoding/base_encoder.py\", line 113, in _check_na\n    _check_optional_contains_na(X, variables)\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/feature_engine/dataframe_checks.py\", line 292, in _check_optional_contains_na\n    raise ValueError(\nValueError: Some of the variables in the dataset contain NaN. Check and remove those before using this transformer or set the parameter `missing_values='ignore'` when initialising this transformer.\n"
     ]
    }
   ],
   "source": [
    "search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n",
    "search.fit(X_train, y_train, scoring='r2', n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a05faa4",
   "metadata": {},
   "source": [
    "Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c495cdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
    "grid_search_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdf137a",
   "metadata": {},
   "source": [
    "### Do an extensive search on the most suitable model to find the best hyperparameter configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9d1cdd",
   "metadata": {},
   "source": [
    "Define model and parameters, for Extensive Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0293e147",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_search = {\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(),\n",
    "}\n",
    "\n",
    "# documentation to help on hyperparameter list: \n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\n",
    "\n",
    "# We will not conduct an extensive search, since the focus\n",
    "# is on how to combine all knowledge in an applied project.\n",
    "# In a workplace project, you may consider more hyperparameters and spend more time in this step\n",
    "\n",
    "params_search = {\n",
    "    \"RandomForestRegressor\": {\n",
    "        'model__n_estimators': [100,300],\n",
    "        'model__max_depth': [3,10,None],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c194b5",
   "metadata": {},
   "source": [
    "Extensive GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cd264b",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = Hyperain, y_parameterOptimizationSearch(models=models_search, params=params_search)\n",
    "search.fit(X_trtrain, scoring = 'r2', n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0580f6",
   "metadata": {},
   "source": [
    "Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76aa00c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
    "grid_search_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfb164a",
   "metadata": {},
   "source": [
    "Check the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffff1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search_summary.iloc[0, 0]\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f05cca",
   "metadata": {},
   "source": [
    "Parameters for best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e277cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_pipelines[best_model].best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166e762d",
   "metadata": {},
   "source": [
    "Define the best regressor, based on search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1ffb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_regressor_pipeline = grid_search_pipelines[best_model].best_estimator_\n",
    "best_regressor_pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a68e3d",
   "metadata": {},
   "source": [
    "## Assess feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f773fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# after data cleaning and feature engineering, the features may have changes\n",
    "# how many data cleaning and feature engineering steps does your pipeline have?\n",
    "data_cleaning_feat_eng_steps = 2\n",
    "columns_after_data_cleaning_feat_eng = (Pipeline(best_regressor_pipeline.steps[:data_cleaning_feat_eng_steps])\n",
    "                                        .transform(X_train)\n",
    "                                        .columns)\n",
    "\n",
    "best_features = columns_after_data_cleaning_feat_eng[best_regressor_pipeline['feat_selection'].get_support(\n",
    ")].to_list()\n",
    "\n",
    "# create DataFrame to display feature importance\n",
    "df_feature_importance = (pd.DataFrame(data={\n",
    "    'Feature': columns_after_data_cleaning_feat_eng[best_regressor_pipeline['feat_selection'].get_support()],\n",
    "    'Importance': best_regressor_pipeline['model'].feature_importances_})\n",
    "    .sort_values(by='Importance', ascending=False)\n",
    ")\n",
    "\n",
    "# Most important features statement and plot\n",
    "print(f\"* These are the {len(best_features)} most important features in descending order. \"\n",
    "      f\"The model was trained on them: \\n{df_feature_importance['Feature'].to_list()}\")\n",
    "\n",
    "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8d798f",
   "metadata": {},
   "source": [
    "## Evaluate on Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e05cdabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def regression_performance(X_train, y_train, X_test, y_test, pipeline):\n",
    "    print(\"Model Evaluation \\n\")\n",
    "    print(\"* Train Set\")\n",
    "    regression_evaluation(X_train, y_train, pipeline)\n",
    "    print(\"* Test Set\")\n",
    "    regression_evaluation(X_test, y_test, pipeline)\n",
    "\n",
    "\n",
    "def regression_evaluation(X, y, pipeline):\n",
    "    prediction = pipeline.predict(X)\n",
    "    print('R2 Score:', r2_score(y, prediction).round(3))\n",
    "    print('Mean Absolute Error:', mean_absolute_error(y, prediction).round(3))\n",
    "    print('Mean Squared Error:', mean_squared_error(y, prediction).round(3))\n",
    "    print('Root Mean Squared Error:', np.sqrt(\n",
    "        mean_squared_error(y, prediction)).round(3))\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "def regression_evaluation_plots(X_train, y_train, X_test, y_test, pipeline, alpha_scatter=0.5):\n",
    "    pred_train = pipeline.predict(X_train)\n",
    "    pred_test = pipeline.predict(X_test)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "    sns.scatterplot(x=y_train, y=pred_train, alpha=alpha_scatter, ax=axes[0])\n",
    "    sns.lineplot(x=y_train, y=y_train, color='red', ax=axes[0])\n",
    "    axes[0].set_xlabel(\"Actual\")\n",
    "    axes[0].set_ylabel(\"Predictions\")\n",
    "    axes[0].set_title(\"Train Set\")\n",
    "\n",
    "    sns.scatterplot(x=y_test, y=pred_test, alpha=alpha_scatter, ax=axes[1])\n",
    "    sns.lineplot(x=y_test, y=y_test, color='red', ax=axes[1])\n",
    "    axes[1].set_xlabel(\"Actual\")\n",
    "    axes[1].set_ylabel(\"Predictions\")\n",
    "    axes[1].set_title(\"Test Set\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38329a40",
   "metadata": {},
   "source": [
    "Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d3a95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_performance(X_train, y_train, X_test, y_test, best_regressor_pipeline)\n",
    "regression_evaluation_plots(X_train, y_train, X_test, y_test, best_regressor_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d815d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = grid_search_pipelines[best_model].best_estimator_\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac008e2",
   "metadata": {},
   "source": [
    "# Which pipeline to choose?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed861d5",
   "metadata": {},
   "source": [
    "We fitted 3 pipelines:\n",
    "* Regression\n",
    "* Regression with PCA\n",
    "* Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec0f343",
   "metadata": {},
   "source": [
    "The regressor pipelines didn't reach the expected performance threshold (0.7 R2 score) for the train and test set.\n",
    "\n",
    "The classifier was tuned on Recall for class 0 (tenure <4 months), since we are interested to detect prospects that may churn soon. \n",
    "* It has reasonable performance for class 0 (<4 months) and class 2 (+20 months)\n",
    "* Class 1 (4 to 20 months) has weak performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad71545",
   "metadata": {},
   "source": [
    "# Refit pipeline with best features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e34bb99",
   "metadata": {},
   "source": [
    "## Rewrite Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecf9411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PipelineOptimization(model):\n",
    "    pipeline_base = Pipeline([\n",
    "\n",
    "        (\"OrdinalCategoricalEncoder\", OrdinalEncoder(encoding_method='arbitrary', variables=['KitchenQual'])),\n",
    "\n",
    "        (\"feat_scaling\", StandardScaler()),\n",
    "\n",
    "        # feature selection is not needed\n",
    "\n",
    "        (\"model\", model),\n",
    "\n",
    "    ])\n",
    "\n",
    "    return pipeline_base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04bf545",
   "metadata": {},
   "source": [
    "## Split Train Test Set, only with best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a109f124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Train set: (1168, 13) (1168,) \n",
      "* Test set: (292, 13) (292,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(['SalePrice'], axis=1),\n",
    "    df['SalePrice'],\n",
    "    test_size=0.2,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "print(\"* Train set:\", X_train.shape, y_train.shape,\n",
    "      \"\\n* Test set:\",  X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982b011c",
   "metadata": {},
   "source": [
    "Subset Best Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4856edf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Train set: (1168, 4) (1168,) \n",
      "* Test set: (292, 4) (292,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>YearBuilt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>774</td>\n",
       "      <td>1828</td>\n",
       "      <td>1822</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>308</td>\n",
       "      <td>894</td>\n",
       "      <td>894</td>\n",
       "      <td>1962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>432</td>\n",
       "      <td>964</td>\n",
       "      <td>876</td>\n",
       "      <td>1921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     GarageArea  GrLivArea  TotalBsmtSF  YearBuilt\n",
       "618         774       1828         1822       2007\n",
       "870         308        894          894       1962\n",
       "92          432        964          876       1921"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.filter(best_features)\n",
    "X_test = X_test.filter(best_features)\n",
    "\n",
    "print(\"* Train set:\", X_train.shape, y_train.shape, \"\\n* Test set:\",  X_test.shape, y_test.shape)\n",
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9396b24",
   "metadata": {},
   "source": [
    "## Grid Search CV – Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7cd294",
   "metadata": {},
   "source": [
    "We are using the same model from the previous GridCV search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4662895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;OrdinalCategoricalEncoder&#x27;,\n",
       "                 OrdinalEncoder(encoding_method=&#x27;arbitrary&#x27;,\n",
       "                                variables=[&#x27;KitchenQual&#x27;])),\n",
       "                (&#x27;SmartCorrelatedSelection&#x27;,\n",
       "                 SmartCorrelatedSelection(method=&#x27;spearman&#x27;,\n",
       "                                          selection_method=&#x27;variance&#x27;,\n",
       "                                          threshold=0.6)),\n",
       "                (&#x27;feat_scaling&#x27;, StandardScaler()),\n",
       "                (&#x27;feat_selection&#x27;,\n",
       "                 SelectFromModel(estimator=RandomForestRegressor())),\n",
       "                (&#x27;model&#x27;, RandomForestRegressor(n_estimators=300))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;OrdinalCategoricalEncoder&#x27;,\n",
       "                 OrdinalEncoder(encoding_method=&#x27;arbitrary&#x27;,\n",
       "                                variables=[&#x27;KitchenQual&#x27;])),\n",
       "                (&#x27;SmartCorrelatedSelection&#x27;,\n",
       "                 SmartCorrelatedSelection(method=&#x27;spearman&#x27;,\n",
       "                                          selection_method=&#x27;variance&#x27;,\n",
       "                                          threshold=0.6)),\n",
       "                (&#x27;feat_scaling&#x27;, StandardScaler()),\n",
       "                (&#x27;feat_selection&#x27;,\n",
       "                 SelectFromModel(estimator=RandomForestRegressor())),\n",
       "                (&#x27;model&#x27;, RandomForestRegressor(n_estimators=300))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder(encoding_method=&#x27;arbitrary&#x27;, variables=[&#x27;KitchenQual&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SmartCorrelatedSelection</label><div class=\"sk-toggleable__content\"><pre>SmartCorrelatedSelection(method=&#x27;spearman&#x27;, selection_method=&#x27;variance&#x27;,\n",
       "                         threshold=0.6)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">feat_selection: SelectFromModel</label><div class=\"sk-toggleable__content\"><pre>SelectFromModel(estimator=RandomForestRegressor())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=300)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('OrdinalCategoricalEncoder',\n",
       "                 OrdinalEncoder(encoding_method='arbitrary',\n",
       "                                variables=['KitchenQual'])),\n",
       "                ('SmartCorrelatedSelection',\n",
       "                 SmartCorrelatedSelection(method='spearman',\n",
       "                                          selection_method='variance',\n",
       "                                          threshold=0.6)),\n",
       "                ('feat_scaling', StandardScaler()),\n",
       "                ('feat_selection',\n",
       "                 SelectFromModel(estimator=RandomForestRegressor())),\n",
       "                ('model', RandomForestRegressor(n_estimators=300))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83b9c8b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RandomForestRegressor': RandomForestRegressor()}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945f496f",
   "metadata": {},
   "source": [
    "And the best parameters from the previous GridCV search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2e0b7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__max_depth': None, 'model__n_estimators': 300}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_pipelines[best_model].best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8da659",
   "metadata": {},
   "source": [
    "You will need to type in manually since the hyperparameter values have to be a list. The previous dictionary is not in this format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "392a75dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_search = {'RandomForrestRegressor':  {\n",
    "    'model__learning_rate': [0.01],   # the value should be in []\n",
    "    'model__max_depth': [3],          # the value should be in []\n",
    "    'model__n_estimators': [300]       # the value should be in []\n",
    "}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d4512d",
   "metadata": {},
   "source": [
    "GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8fc346c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running GridSearchCV for LinearRegression \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 423, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 377, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/joblib/memory.py\", line 326, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 957, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/utils/_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/base.py\", line 919, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/feature_engine/encoding/ordinal.py\", line 201, in fit\n    variables_ = self._check_or_select_variables(X)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/feature_engine/encoding/base_encoder.py\", line 135, in _check_or_select_variables\n    variables_: List[Union[str, int]] = find_or_check_categorical_variables(\n                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/feature_engine/variable_handling/variable_type_selection.py\", line 156, in find_or_check_categorical_variables\n    if len(X[variables].select_dtypes(exclude=[\"O\", \"category\"]).columns) > 0:\n           ~^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/pandas/core/frame.py\", line 3902, in __getitem__\n    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6114, in _get_indexer_strict\n    self._raise_if_missing(keyarr, indexer, axis_name)\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6175, in _raise_if_missing\n    raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\nKeyError: \"None of [Index(['KitchenQual'], dtype='object')] are in the [columns]\"\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m search \u001b[38;5;241m=\u001b[39m HyperparameterOptimizationSearch(models\u001b[38;5;241m=\u001b[39mmodels_quick_search, params\u001b[38;5;241m=\u001b[39mparams_quick_search)\n\u001b[0;32m----> 2\u001b[0m \u001b[43msearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 20\u001b[0m, in \u001b[0;36mHyperparameterOptimizationSearch.fit\u001b[0;34m(self, X, y, cv, n_jobs, verbose, scoring, refit)\u001b[0m\n\u001b[1;32m     17\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[key]\n\u001b[1;32m     18\u001b[0m gs \u001b[38;5;241m=\u001b[39m GridSearchCV(model, params, cv\u001b[38;5;241m=\u001b[39mcv, n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[1;32m     19\u001b[0m                   verbose\u001b[38;5;241m=\u001b[39mverbose, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrid_searches[key] \u001b[38;5;241m=\u001b[39m gs\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1422\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    870\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    873\u001b[0m     )\n\u001b[0;32m--> 875\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    408\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    412\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    413\u001b[0m     )\n\u001b[0;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    418\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    419\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    424\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 423, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 377, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/joblib/memory.py\", line 326, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 957, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/utils/_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/base.py\", line 919, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/feature_engine/encoding/ordinal.py\", line 201, in fit\n    variables_ = self._check_or_select_variables(X)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/feature_engine/encoding/base_encoder.py\", line 135, in _check_or_select_variables\n    variables_: List[Union[str, int]] = find_or_check_categorical_variables(\n                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/feature_engine/variable_handling/variable_type_selection.py\", line 156, in find_or_check_categorical_variables\n    if len(X[variables].select_dtypes(exclude=[\"O\", \"category\"]).columns) > 0:\n           ~^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/pandas/core/frame.py\", line 3902, in __getitem__\n    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6114, in _get_indexer_strict\n    self._raise_if_missing(keyarr, indexer, axis_name)\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6175, in _raise_if_missing\n    raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\nKeyError: \"None of [Index(['KitchenQual'], dtype='object')] are in the [columns]\"\n"
     ]
    }
   ],
   "source": [
    "search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n",
    "search.fit(X_train, y_train, scoring='r2', n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99da6eee",
   "metadata": {},
   "source": [
    "\n",
    "Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "16a4f630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>std_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.679313</td>\n",
       "      <td>0.802884</td>\n",
       "      <td>0.85964</td>\n",
       "      <td>0.066075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.617934</td>\n",
       "      <td>0.79126</td>\n",
       "      <td>0.857411</td>\n",
       "      <td>0.089492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.648767</td>\n",
       "      <td>0.764103</td>\n",
       "      <td>0.827152</td>\n",
       "      <td>0.07687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.61548</td>\n",
       "      <td>0.763092</td>\n",
       "      <td>0.850056</td>\n",
       "      <td>0.099405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.662875</td>\n",
       "      <td>0.755913</td>\n",
       "      <td>0.796436</td>\n",
       "      <td>0.048362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>0.600973</td>\n",
       "      <td>0.715002</td>\n",
       "      <td>0.775794</td>\n",
       "      <td>0.067055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>0.535523</td>\n",
       "      <td>0.657988</td>\n",
       "      <td>0.756389</td>\n",
       "      <td>0.084346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   estimator min_score mean_score max_score std_score\n",
       "2      RandomForestRegressor  0.679313   0.802884   0.85964  0.066075\n",
       "3        ExtraTreesRegressor  0.617934    0.79126  0.857411  0.089492\n",
       "6               XGBRegressor  0.648767   0.764103  0.827152   0.07687\n",
       "5  GradientBoostingRegressor   0.61548   0.763092  0.850056  0.099405\n",
       "0           LinearRegression  0.662875   0.755913  0.796436  0.048362\n",
       "4          AdaBoostRegressor  0.600973   0.715002  0.775794  0.067055\n",
       "1      DecisionTreeRegressor  0.535523   0.657988  0.756389  0.084346"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
    "grid_search_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f714c05e",
   "metadata": {},
   "source": [
    "Check the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bb99500e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RandomForestRegressor'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = grid_search_summary.iloc[0,0]\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83d5f42",
   "metadata": {},
   "source": [
    "Define the best pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e5ed05b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;feat_scaling&#x27;, StandardScaler()),\n",
       "                (&#x27;model&#x27;, RandomForestRegressor(random_state=0))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;feat_scaling&#x27;, StandardScaler()),\n",
       "                (&#x27;model&#x27;, RandomForestRegressor(random_state=0))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=0)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('feat_scaling', StandardScaler()),\n",
       "                ('model', RandomForestRegressor(random_state=0))])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = grid_search_pipelines[best_model].best_estimator_\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11346c27",
   "metadata": {},
   "source": [
    "## Assess feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f204f94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# after data cleaning and feature engineering, the features may have changes\n",
    "# how many data cleaning and feature engineering steps does your pipeline have?\n",
    "data_cleaning_feat_eng_steps = 2\n",
    "columns_after_data_cleaning_feat_eng = (Pipeline(best_regressor_pipeline.steps[:data_cleaning_feat_eng_steps])\n",
    "                                        .transform(X_train)\n",
    "                                        .columns)\n",
    "\n",
    "best_features = columns_after_data_cleaning_feat_eng[best_regressor_pipeline['feat_selection'].get_support(\n",
    ")].to_list()\n",
    "\n",
    "# create DataFrame to display feature importance\n",
    "df_feature_importance = (pd.DataFrame(data={\n",
    "    'Feature': columns_after_data_cleaning_feat_eng[best_regressor_pipeline['feat_selection'].get_support()],\n",
    "    'Importance': best_regressor_pipeline['model'].feature_importances_})\n",
    "    .sort_values(by='Importance', ascending=False)\n",
    ")\n",
    "\n",
    "# Most important features statement and plot\n",
    "print(f\"* These are the {len(best_features)} most important features in descending order. \"\n",
    "      f\"The model was trained on them: \\n{df_feature_importance['Feature'].to_list()}\")\n",
    "\n",
    "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f3df01",
   "metadata": {},
   "source": [
    "## Evaluate Classifier on Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6372a1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf_performance(X_train=X_train, y_train=y_train,\n",
    "#                         X_test=X_test, y_test=y_test,\n",
    "#                         pipeline=pipeline_clf,\n",
    "#                         label_map= label_map )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c302adaf",
   "metadata": {},
   "source": [
    "# Push files to the repo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c267909",
   "metadata": {},
   "source": [
    "We will generate the following files\n",
    "\n",
    "* Train set\n",
    "* Test set\n",
    "* Modeling pipeline\n",
    "* label map\n",
    "* features importance plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "62d52356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "version = 'v1'\n",
    "file_path = f'outputs/ml_pipeline/predict_sale_price/{version}'\n",
    "\n",
    "try:\n",
    "  os.makedirs(name=file_path)\n",
    "except Exception as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456da697",
   "metadata": {},
   "source": [
    "## Train Set: features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e114592e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>1828</td>\n",
       "      <td>48</td>\n",
       "      <td>1774</td>\n",
       "      <td>774</td>\n",
       "      <td>1828</td>\n",
       "      <td>Gd</td>\n",
       "      <td>11694</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1822</td>\n",
       "      <td>2007</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "      <td>894</td>\n",
       "      <td>308</td>\n",
       "      <td>894</td>\n",
       "      <td>TA</td>\n",
       "      <td>6600</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>894</td>\n",
       "      <td>1962</td>\n",
       "      <td>1962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>964</td>\n",
       "      <td>713</td>\n",
       "      <td>163</td>\n",
       "      <td>432</td>\n",
       "      <td>964</td>\n",
       "      <td>TA</td>\n",
       "      <td>13360</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>876</td>\n",
       "      <td>1921</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>1689</td>\n",
       "      <td>1218</td>\n",
       "      <td>350</td>\n",
       "      <td>857</td>\n",
       "      <td>1689</td>\n",
       "      <td>Gd</td>\n",
       "      <td>13265</td>\n",
       "      <td>59</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1568</td>\n",
       "      <td>2002</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>1541</td>\n",
       "      <td>0</td>\n",
       "      <td>1541</td>\n",
       "      <td>843</td>\n",
       "      <td>1541</td>\n",
       "      <td>Gd</td>\n",
       "      <td>13704</td>\n",
       "      <td>81</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1541</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     1stFlrSF  BsmtFinSF1  BsmtUnfSF  GarageArea  GrLivArea KitchenQual  \\\n",
       "618      1828          48       1774         774       1828          Gd   \n",
       "870       894           0        894         308        894          TA   \n",
       "92        964         713        163         432        964          TA   \n",
       "817      1689        1218        350         857       1689          Gd   \n",
       "302      1541           0       1541         843       1541          Gd   \n",
       "\n",
       "     LotArea  OpenPorchSF  OverallCond  OverallQual  TotalBsmtSF  YearBuilt  \\\n",
       "618    11694          108            5            9         1822       2007   \n",
       "870     6600            0            5            5          894       1962   \n",
       "92     13360            0            7            5          876       1921   \n",
       "817    13265           59            5            8         1568       2002   \n",
       "302    13704           81            5            7         1541       2001   \n",
       "\n",
       "     YearRemodAdd  \n",
       "618          2007  \n",
       "870          1962  \n",
       "92           2006  \n",
       "817          2002  \n",
       "302          2002  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "55d76e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.to_csv(f\"{file_path}/X_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a238651d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b4cfcebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train.to_csv(f\"{file_path}/y_train.csv\", index=lse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6889177f",
   "metadata": {},
   "source": [
    "## Test Set: features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5bd59e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "22e32bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test.to_csv(f\"{file_path}/X_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "987fe1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "29fb2b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.to_csv(f\"{file_path}/y_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe2b34c",
   "metadata": {},
   "source": [
    "## Modelling pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49016506",
   "metadata": {},
   "source": [
    "ML pipeline for predicting tenure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a5870a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5b406aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(value=pipeline_clf, filename=f\"{file_path}/clf_pipeline.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585dff07",
   "metadata": {},
   "source": [
    "## List  mapping target levels to ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c118d2",
   "metadata": {},
   "source": [
    "Map for converting numerical variable to categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bdae5e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3903e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(value=label_map, filename=f\"{file_path}/label_map.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c129322",
   "metadata": {},
   "source": [
    "## Feature importance plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de01cff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "122a2e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_feature_importance.plot(kind='bar',x='Feature',y='Importance')\n",
    "# plt.savefig(f'{file_path}/features_importance.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a58900e",
   "metadata": {},
   "source": [
    "End"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f946f7c",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
