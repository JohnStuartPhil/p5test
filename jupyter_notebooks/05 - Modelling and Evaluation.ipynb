{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8228f95c",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94d09ac",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "*   Fit and evaluate a regression model to predict tenure levels for a prospect that will likely churn\n",
    "\n",
    "\n",
    "## Inputs\n",
    "\n",
    "* outputs/datasets/collection/HousePriceRecords.csv\n",
    "* Instructions on which variables to use for data cleaning and feature engineering. They are found in their respective notebooks.\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* Train set (features and target)\n",
    "* Test set (features and target)\n",
    "* ML pipeline to predict Sale Price\n",
    "* labels map\n",
    "* Feature Importance Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b322bb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8b7569",
   "metadata": {},
   "source": [
    "# Change working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c276af77",
   "metadata": {},
   "source": [
    "We need to change the working directory from its current folder to its parent folder\n",
    "* We access the current directory with os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdc33e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/p5test/jupyter_notebooks'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92305b5a",
   "metadata": {},
   "source": [
    "We want to make the parent of the current directory the new current directory.\n",
    "* os.path.dirname() gets the parent directory\n",
    "* os.chir() defines the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1f3c006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You set a new current directory\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27240028",
   "metadata": {},
   "source": [
    "Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18ca3561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/p5test'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8887717",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a3304c",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82dac84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>...</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>856</td>\n",
       "      <td>854.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>No</td>\n",
       "      <td>706</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>548</td>\n",
       "      <td>RFn</td>\n",
       "      <td>...</td>\n",
       "      <td>65.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>978</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>460</td>\n",
       "      <td>RFn</td>\n",
       "      <td>...</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>920</td>\n",
       "      <td>866.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Mn</td>\n",
       "      <td>486</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>434</td>\n",
       "      <td>0.0</td>\n",
       "      <td>608</td>\n",
       "      <td>RFn</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  BedroomAbvGr BsmtExposure  BsmtFinSF1 BsmtFinType1  \\\n",
       "0       856     854.0           3.0           No         706          GLQ   \n",
       "1      1262       0.0           3.0           Gd         978          ALQ   \n",
       "2       920     866.0           3.0           Mn         486          GLQ   \n",
       "\n",
       "   BsmtUnfSF  EnclosedPorch  GarageArea GarageFinish  ...  LotFrontage  \\\n",
       "0        150            0.0         548          RFn  ...         65.0   \n",
       "1        284            NaN         460          RFn  ...         80.0   \n",
       "2        434            0.0         608          RFn  ...         68.0   \n",
       "\n",
       "   MasVnrArea OpenPorchSF  OverallCond  OverallQual  TotalBsmtSF  WoodDeckSF  \\\n",
       "0       196.0          61            5            7          856         0.0   \n",
       "1         0.0           0            8            6         1262         NaN   \n",
       "2       162.0          42            5            7          920         NaN   \n",
       "\n",
       "   YearBuilt  YearRemodAdd  SalePrice  \n",
       "0       2003          2003     208500  \n",
       "1       1976          1976     181500  \n",
       "2       2001          2002     223500  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = (pd.read_csv(\"outputs/datasets/collection/HousePriceRecords.csv\")\n",
    "      #.query(\"Churn == 1\")  # subset churned customer\n",
    "      #.drop(labels=['customerID', 'TotalCharges', 'Churn'], axis=1)\n",
    "      # variables we will not need for this project\n",
    "      # we will not need Churn since it has only 1\n",
    "      )\n",
    "\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3f8aed",
   "metadata": {},
   "source": [
    "# MP Pipeline: Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6061ea",
   "metadata": {},
   "source": [
    "## Create ML pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b5df1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Feature Engineering\n",
    "from feature_engine.encoding import OrdinalEncoder\n",
    "from feature_engine.selection import SmartCorrelatedSelection\n",
    "\n",
    "# Feat Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Feat Selection\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# ML algorithms\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "\n",
    "def PipelineOptimization(model):\n",
    "    pipeline_base = Pipeline([\n",
    "\n",
    "        (\"OrdinalCategoricalEncoder\", OrdinalEncoder(encoding_method='arbitrary',\n",
    "                                                     variables=['BsmtExposure', 'BsmtFinType1', 'GarageFinish'])),\n",
    "\n",
    "\n",
    "        (\"SmartCorrelatedSelection\", SmartCorrelatedSelection(variables=None,\n",
    "         method=\"spearman\", threshold=0.6, selection_method=\"variance\")),\n",
    "\n",
    "        (\"feat_scaling\", StandardScaler()),\n",
    "\n",
    "        (\"feat_selection\",  SelectFromModel(model)),\n",
    "\n",
    "        (\"model\", model),\n",
    "\n",
    "    ])\n",
    "\n",
    "    return pipeline_base\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb29b6e",
   "metadata": {},
   "source": [
    "Custom Class for hyperparameter optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4514fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "class HyperparameterOptimizationSearch:\n",
    "\n",
    "    def __init__(self, models, params):\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
    "            model = PipelineOptimization(self.models[key])\n",
    "\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=scoring)\n",
    "            gs.fit(X, y)\n",
    "            self.grid_searches[key] = gs\n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                'estimator': key,\n",
    "                'min_score': min(scores),\n",
    "                'max_score': max(scores),\n",
    "                'mean_score': np.mean(scores),\n",
    "                'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params, **d})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]\n",
    "                scores.append(r.reshape(len(params), 1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params, all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "\n",
    "        columns = ['estimator', 'min_score',\n",
    "                   'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "\n",
    "        return df[columns], self.grid_searches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3231d8",
   "metadata": {},
   "source": [
    "## Split Train Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06d58b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Train set: (1168, 23) (1168,) \n",
      "* Test set: (292, 23) (292,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(['SalePrice'], axis=1),\n",
    "    df['SalePrice'],\n",
    "    test_size=0.2,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "print(\"* Train set:\", X_train.shape, y_train.shape,\n",
    "      \"\\n* Test set:\",  X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2313a905",
   "metadata": {},
   "source": [
    "## Grid Search CV - Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af38815",
   "metadata": {},
   "source": [
    "### Use default hyperparameters to find most suitable algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6927cf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_quick_search = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    \"DecisionTreeRegressor\": DecisionTreeRegressor(random_state=0),\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(random_state=0),\n",
    "    \"ExtraTreesRegressor\": ExtraTreesRegressor(random_state=0),\n",
    "    \"AdaBoostRegressor\": AdaBoostRegressor(random_state=0),\n",
    "    \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0),\n",
    "    \"XGBRegressor\": XGBRegressor(random_state=0),\n",
    "}\n",
    "\n",
    "params_quick_search = {\n",
    "    'LinearRegression': {},\n",
    "    \"DecisionTreeRegressor\": {},\n",
    "    \"RandomForestRegressor\": {},\n",
    "    \"ExtraTreesRegressor\": {},\n",
    "    \"AdaBoostRegressor\": {},\n",
    "    \"GradientBoostingRegressor\": {},\n",
    "    \"XGBRegressor\": {},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d726fb20",
   "metadata": {},
   "source": [
    "Do a hyperparameter optimisation search using default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e504fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running GridSearchCV for LinearRegression \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/pipeline.py\", line 423, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/pipeline.py\", line 377, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/codespace/.local/lib/python3.12/site-packages/joblib/memory.py\", line 326, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/pipeline.py\", line 957, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/utils/_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/base.py\", line 919, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/feature_engine/encoding/ordinal.py\", line 202, in fit\n    self._check_na(X, variables_)\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/feature_engine/encoding/base_encoder.py\", line 113, in _check_na\n    _check_optional_contains_na(X, variables)\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/feature_engine/dataframe_checks.py\", line 292, in _check_optional_contains_na\n    raise ValueError(\nValueError: Some of the variables in the dataset contain NaN. Check and remove those before using this transformer or set the parameter `missing_values='ignore'` when initialising this transformer.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43msearch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr2\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mHyperparameterOptimizationSearch.fit\u001b[39m\u001b[34m(self, X, y, cv, n_jobs, verbose, scoring, refit)\u001b[39m\n\u001b[32m     17\u001b[39m params = \u001b[38;5;28mself\u001b[39m.params[key]\n\u001b[32m     18\u001b[39m gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n\u001b[32m     19\u001b[39m                   verbose=verbose, scoring=scoring)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[43mgs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;28mself\u001b[39m.grid_searches[key] = gs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/base.py:1152\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1145\u001b[39m     estimator._validate_params()\n\u001b[32m   1147\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1148\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1149\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1150\u001b[39m     )\n\u001b[32m   1151\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1152\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/model_selection/_search.py:898\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, groups, **fit_params)\u001b[39m\n\u001b[32m    892\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m    893\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m    894\u001b[39m     )\n\u001b[32m    896\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m--> \u001b[39m\u001b[32m898\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m    901\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m    902\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1422\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1420\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1421\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1422\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/model_selection/_search.py:875\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) != n_candidates * n_splits:\n\u001b[32m    869\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    870\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcv.split and cv.get_n_splits returned \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    871\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    872\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(n_splits, \u001b[38;5;28mlen\u001b[39m(out) // n_candidates)\n\u001b[32m    873\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m875\u001b[39m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[32m    878\u001b[39m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[32m    879\u001b[39m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[32m    880\u001b[39m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.scoring):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:414\u001b[39m, in \u001b[36m_warn_or_raise_about_fit_failures\u001b[39m\u001b[34m(results, error_score)\u001b[39m\n\u001b[32m    407\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits == num_fits:\n\u001b[32m    408\u001b[39m     all_fits_failed_message = (\n\u001b[32m    409\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    410\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    411\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou can try to debug the error by setting error_score=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    412\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    413\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m414\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    417\u001b[39m     some_fits_failed_message = (\n\u001b[32m    418\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    419\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe score on these train-test partitions for these parameters\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    423\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    424\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/pipeline.py\", line 423, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/pipeline.py\", line 377, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/codespace/.local/lib/python3.12/site-packages/joblib/memory.py\", line 326, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/pipeline.py\", line 957, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/utils/_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/base.py\", line 919, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/feature_engine/encoding/ordinal.py\", line 202, in fit\n    self._check_na(X, variables_)\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/feature_engine/encoding/base_encoder.py\", line 113, in _check_na\n    _check_optional_contains_na(X, variables)\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/feature_engine/dataframe_checks.py\", line 292, in _check_optional_contains_na\n    raise ValueError(\nValueError: Some of the variables in the dataset contain NaN. Check and remove those before using this transformer or set the parameter `missing_values='ignore'` when initialising this transformer.\n"
     ]
    }
   ],
   "source": [
    "search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n",
    "search.fit(X_train, y_train, scoring='r2', n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a05faa4",
   "metadata": {},
   "source": [
    "Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c495cdf6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'search' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m grid_search_summary, grid_search_pipelines = \u001b[43msearch\u001b[49m.score_summary(sort_by=\u001b[33m'\u001b[39m\u001b[33mmean_score\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m grid_search_summary\n",
      "\u001b[31mNameError\u001b[39m: name 'search' is not defined"
     ]
    }
   ],
   "source": [
    "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
    "grid_search_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdf137a",
   "metadata": {},
   "source": [
    "### Do an extensive search on the most suitable model to find the best hyperparameter configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9d1cdd",
   "metadata": {},
   "source": [
    "Define model and parameters, for Extensive Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0293e147",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GradientBoostingRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m models_search = {\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mGradientBoostingRegressor\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mGradientBoostingRegressor\u001b[49m(random_state=\u001b[32m0\u001b[39m),\n\u001b[32m      3\u001b[39m }\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# documentation to help on hyperparameter list: \u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\u001b[39;00m\n\u001b[32m      7\u001b[39m \n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# We will not conduct an extensive search, since the focus\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# is on how to combine all knowledge in an applied project.\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# In a workplace project, you may consider more hyperparameters and spend more time in this step\u001b[39;00m\n\u001b[32m     12\u001b[39m params_search = {\n\u001b[32m     13\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mGradientBoostingRegressor\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m     14\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mmodel__n_estimators\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m100\u001b[39m,\u001b[32m300\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m     }\n\u001b[32m     18\u001b[39m }\n",
      "\u001b[31mNameError\u001b[39m: name 'GradientBoostingRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "models_search = {\n",
    "    \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0),\n",
    "}\n",
    "\n",
    "# documentation to help on hyperparameter list: \n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\n",
    "\n",
    "# We will not conduct an extensive search, since the focus\n",
    "# is on how to combine all knowledge in an applied project.\n",
    "# In a workplace project, you may consider more hyperparameters and spend more time in this step\n",
    "\n",
    "params_search = {\n",
    "    \"GradientBoostingRegressor\": {\n",
    "        'model__n_estimators': [100,300],\n",
    "        'model__learning_rate': [1e-1,1e-2,1e-3], \n",
    "        'model__max_depth': [3,10,None],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c194b5",
   "metadata": {},
   "source": [
    "Extensive GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54cd264b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'HyperparameterOptimizationSearch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m search = \u001b[43mHyperparameterOptimizationSearch\u001b[49m(models=models_search, params=params_search)\n\u001b[32m      2\u001b[39m search.fit(X_train, y_train, scoring = \u001b[33m'\u001b[39m\u001b[33mr2\u001b[39m\u001b[33m'\u001b[39m, n_jobs=-\u001b[32m1\u001b[39m, cv=\u001b[32m5\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'HyperparameterOptimizationSearch' is not defined"
     ]
    }
   ],
   "source": [
    "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
    "search.fit(X_train, y_train, scoring = 'r2', n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0580f6",
   "metadata": {},
   "source": [
    "Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76aa00c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'search' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m grid_search_summary, grid_search_pipelines = \u001b[43msearch\u001b[49m.score_summary(sort_by=\u001b[33m'\u001b[39m\u001b[33mmean_score\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m grid_search_summary\n",
      "\u001b[31mNameError\u001b[39m: name 'search' is not defined"
     ]
    }
   ],
   "source": [
    "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
    "grid_search_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfb164a",
   "metadata": {},
   "source": [
    "Check the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ffff1e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_search_summary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m best_model = \u001b[43mgrid_search_summary\u001b[49m.iloc[\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m]\n\u001b[32m      2\u001b[39m best_model\n",
      "\u001b[31mNameError\u001b[39m: name 'grid_search_summary' is not defined"
     ]
    }
   ],
   "source": [
    "best_model = grid_search_summary.iloc[0, 0]\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f05cca",
   "metadata": {},
   "source": [
    "Parameters for best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e277cda",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_search_pipelines' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mgrid_search_pipelines\u001b[49m[best_model].best_params_\n",
      "\u001b[31mNameError\u001b[39m: name 'grid_search_pipelines' is not defined"
     ]
    }
   ],
   "source": [
    "grid_search_pipelines[best_model].best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166e762d",
   "metadata": {},
   "source": [
    "Define the best regressor, based on search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b1ffb95",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_search_pipelines' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m best_regressor_pipeline = \u001b[43mgrid_search_pipelines\u001b[49m[best_model].best_estimator_\n\u001b[32m      2\u001b[39m best_regressor_pipeline\n",
      "\u001b[31mNameError\u001b[39m: name 'grid_search_pipelines' is not defined"
     ]
    }
   ],
   "source": [
    "best_regressor_pipeline = grid_search_pipelines[best_model].best_estimator_\n",
    "best_regressor_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a68e3d",
   "metadata": {},
   "source": [
    "## Assess feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f773fb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# after data cleaning and feature engineering, the features may have changes\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# how many data cleaning and feature engineering steps does your pipeline have?\u001b[39;00m\n\u001b[32m      7\u001b[39m data_cleaning_feat_eng_steps = \u001b[32m2\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m columns_after_data_cleaning_feat_eng = (\u001b[43mPipeline\u001b[49m(best_regressor_pipeline.steps[:data_cleaning_feat_eng_steps])\n\u001b[32m      9\u001b[39m                                         .transform(X_train)\n\u001b[32m     10\u001b[39m                                         .columns)\n\u001b[32m     12\u001b[39m best_features = columns_after_data_cleaning_feat_eng[best_regressor_pipeline[\u001b[33m'\u001b[39m\u001b[33mfeat_selection\u001b[39m\u001b[33m'\u001b[39m].get_support(\n\u001b[32m     13\u001b[39m )].to_list()\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# create DataFrame to display feature importance\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'Pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# after data cleaning and feature engineering, the features may have changes\n",
    "# how many data cleaning and feature engineering steps does your pipeline have?\n",
    "data_cleaning_feat_eng_steps = 2\n",
    "columns_after_data_cleaning_feat_eng = (Pipeline(best_regressor_pipeline.steps[:data_cleaning_feat_eng_steps])\n",
    "                                        .transform(X_train)\n",
    "                                        .columns)\n",
    "\n",
    "best_features = columns_after_data_cleaning_feat_eng[best_regressor_pipeline['feat_selection'].get_support(\n",
    ")].to_list()\n",
    "\n",
    "# create DataFrame to display feature importance\n",
    "df_feature_importance = (pd.DataFrame(data={\n",
    "    'Feature': columns_after_data_cleaning_feat_eng[best_regressor_pipeline['feat_selection'].get_support()],\n",
    "    'Importance': best_regressor_pipeline['model'].feature_importances_})\n",
    "    .sort_values(by='Importance', ascending=False)\n",
    ")\n",
    "\n",
    "# Most important features statement and plot\n",
    "print(f\"* These are the {len(best_features)} most important features in descending order. \"\n",
    "      f\"The model was trained on them: \\n{df_feature_importance['Feature'].to_list()}\")\n",
    "\n",
    "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8d798f",
   "metadata": {},
   "source": [
    "## Evaluate on Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e05cdabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def regression_performance(X_train, y_train, X_test, y_test, pipeline):\n",
    "    print(\"Model Evaluation \\n\")\n",
    "    print(\"* Train Set\")\n",
    "    regression_evaluation(X_train, y_train, pipeline)\n",
    "    print(\"* Test Set\")\n",
    "    regression_evaluation(X_test, y_test, pipeline)\n",
    "\n",
    "\n",
    "def regression_evaluation(X, y, pipeline):\n",
    "    prediction = pipeline.predict(X)\n",
    "    print('R2 Score:', r2_score(y, prediction).round(3))\n",
    "    print('Mean Absolute Error:', mean_absolute_error(y, prediction).round(3))\n",
    "    print('Mean Squared Error:', mean_squared_error(y, prediction).round(3))\n",
    "    print('Root Mean Squared Error:', np.sqrt(\n",
    "        mean_squared_error(y, prediction)).round(3))\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "def regression_evaluation_plots(X_train, y_train, X_test, y_test, pipeline, alpha_scatter=0.5):\n",
    "    pred_train = pipeline.predict(X_train)\n",
    "    pred_test = pipeline.predict(X_test)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "    sns.scatterplot(x=y_train, y=pred_train, alpha=alpha_scatter, ax=axes[0])\n",
    "    sns.lineplot(x=y_train, y=y_train, color='red', ax=axes[0])\n",
    "    axes[0].set_xlabel(\"Actual\")\n",
    "    axes[0].set_ylabel(\"Predictions\")\n",
    "    axes[0].set_title(\"Train Set\")\n",
    "\n",
    "    sns.scatterplot(x=y_test, y=pred_test, alpha=alpha_scatter, ax=axes[1])\n",
    "    sns.lineplot(x=y_test, y=y_test, color='red', ax=axes[1])\n",
    "    axes[1].set_xlabel(\"Actual\")\n",
    "    axes[1].set_ylabel(\"Predictions\")\n",
    "    axes[1].set_title(\"Test Set\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38329a40",
   "metadata": {},
   "source": [
    "Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3d3a95f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m regression_performance(\u001b[43mX_train\u001b[49m, y_train, X_test, y_test, best_regressor_pipeline)\n\u001b[32m      2\u001b[39m regression_evaluation_plots(X_train, y_train, X_test, y_test, best_regressor_pipeline)\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "regression_performance(X_train, y_train, X_test, y_test, best_regressor_pipeline)\n",
    "regression_evaluation_plots(X_train, y_train, X_test, y_test, best_regressor_pipeline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
